有人说，分类和目标检测的剪枝方法不同。真的吗？剪枝的目的就是剪掉网络中的冗余feature map。无论是分类任务还是目标检测，他们的剪枝原理都相同。

那么，有什么不同呢？

特征网络的不同，剪枝方法的不同。比如果深度网络和稠密网络可以用相同的方法剪枝。不同的是如何处理树形分支内容—分之间相似核合并或者单分支剪枝。边缘/移动端网络一般的结构是conv+bn+relu的方式，当然也有树形和稠密的机构，这里只说第一种，它的剪枝方式是根据bn的gamma来确定feature map的重要性。

当然，剪枝的方法选择还可以根据激活函数。比如说prelu和relu可以选的方法就有所不同。

----------

tensorflow和keras相对剪枝来说，某些论文中的算法是实现不了的，这也就是为什么torch/pytorch成为现在可言的首选。但是tf有serving的优势。

为什么tf实现不了？因为tf的运算图机制。